{"training": [{"loss": 1.9793775037173686, "grad_norm": 1.6465835589572668}, {"loss": 1.921118053216664, "grad_norm": 0.7205133387515622}, {"loss": 1.8029998762909993, "grad_norm": 0.9826874885263054}, {"loss": 1.8073350319965866, "grad_norm": 1.4395781127705642}, {"loss": 1.6164943718094518, "grad_norm": 4.639842595930137}, {"loss": 1.6947092255520166, "grad_norm": 2.6632776244883734}, {"loss": 1.7422700177890493, "grad_norm": 2.441032747834898}, {"loss": 1.7334049649409264, "grad_norm": 4.292776270721506}, {"loss": 1.5544717441726081, "grad_norm": 0.6848299456031803}, {"loss": 1.4228845206118383, "grad_norm": 0.41843980346439547}, {"loss": 1.566299341524995, "grad_norm": 2.2603592985094263}, {"loss": 1.361803732405073, "grad_norm": 4.616749741491992}, {"loss": 1.5935159953826883, "grad_norm": 3.7025437336705154}, {"loss": 1.438477485645877, "grad_norm": 1.739976685679963}, {"loss": 1.371466436821303, "grad_norm": 3.5801969934135625}, {"loss": 1.235395881573352, "grad_norm": 0.5132868638413857}, {"loss": 1.0597733231777156, "grad_norm": 3.4358275798665874}, {"loss": 1.1153026956745966, "grad_norm": 0.3187058342226584}, {"loss": 1.0182475596888676, "grad_norm": 4.89783818549879}, {"loss": 0.9936913768118707, "grad_norm": 3.761490791060989}, {"loss": 1.0015369068876387, "grad_norm": 2.735153331146108}, {"loss": 0.8089414862260796, "grad_norm": 3.101967044758781}, {"loss": 0.8179062469063996, "grad_norm": 2.47030403079685}, {"loss": 0.9455037589789097, "grad_norm": 3.5098168678095916}, {"loss": 0.7332549472052124, "grad_norm": 3.322832809249832}]}